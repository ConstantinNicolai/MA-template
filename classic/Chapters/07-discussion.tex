\chapter{Discussion and Outlook}\label{chap:discussion}

\section{Discussion}

The approach we took in this work was of an exploratory nature. Rather than diving deep into one specific configuration, we chose to go wide and look at multiple hardware and many neural network scenarios. That approach turned out to be both a blessing and a curse. A blessing, because the results can be used in a wide field of applications and our findings are understandable at a more abstract level. A curse, because we have to hamper our scientific curiosity not to follow every rabbit hole we encounter along our journey. Given the wide approach, we also discover a wide range is troubleshooting issues which vary in their importance to the study itself. This balancing act of weighing the cost and benefit of following up on interesting trends and deciding whether or not to invest the time to overcome the troubleshooting obstacles was the most difficult part of this work. In order to understand the choices we made concerning the scope, it is important to see that even in our quest to go wide, it lies in the nature of exploratory research, that no state of completeness can ever be achieved. \\
In order to go wide, one would like to include a large number of hardware scenarios and study all of them with the same set of accurate tools. Ideally, we would like to include GPUs from Nvidia, AMD and Intel alongside FPGAs and other ML accelerators. But the platforms and tools are too varied, such that even if we found tooling which was capable of measuring power for all of the above, we would likely give up both time and power resolution in exchange for that improved compatibility. Another simple but very important limitation is the hardware available to us. Both because of these considerations as well as in order to keep the scope of this thesis in check, we decided to limit ourselves to Nvidia GPUs. \\
Another dimension to go wide in, is the plurality of neural networks. Here our decision was determined by our platform of choice. Due to prior experience with the platform we chose PyTorch. In order to use well known networks and implementations, we decided to work with neural networks from the torchvision library. This also improves the easy of reproducing our study. Our GPU with the smallest amount of global memory added a limit to which model-input sets we were able to include in our suite profiled for the training set, since each model-input set had to be able to complete all benchmarks on all hardware configurations. \\
Our choice to study both time and energy for inference and training was shaped by the desire to study a novel section of the field and to add value to our research.  \\
After initial attempts to include both GPUs in the clock speed study, the 2080TI was dropped from this part of the overall study after running into issues.\\
The predictor models for the A30 and the 2080TI only differ in the A30 predictor including clock speed specific predictions. Apart from that they are built identically. In our evaluation of which type of predictor model we want to use, we are therefore looking for the model type that is the most stable across all our scenarios. This will enable it to serve as a recommendation suitable for various settings of neural networks and hardware. \\
With that in mind, let us recap our predictor results. For the 2080TI, the evaluation of the $R^2$ score showed similar or better performance using the random forest model over the XGBoost model for both the training and inference predictors. The evaluation of the A30 predictor revealed slightly better scores using the XGBoost predictor. However, the improvements over the random forest model were much smaller than the drop-off observed for the 2080TI predictor going from random forest to XGBoost. This behavior leads us to believe that the random forest approach serves as a more stable and consistent path across the plurality of hardware configurations this methodology might encounter in the future. \\
Earlier in this discussion it was mentioned that this is an exploratory work. In the same way it is also a foundational work. Each contribution aids to explore which paths can be taken and helps building a foundation of methodology and due diligence. Our work provides the tools for the collection of a required dataset and demonstrates the resilience of the resulting dataset through a direct validation. Since the predominant interest in the research community lies in finding insights regarding complete neural networks, the nature of our validation ensures our findings are applicable to full neural network executions. For the same reasons, the A30 predictor is evaluated on a neural network level. Operations level results might be interesting for a specific academic niche, but they can only fulfill their potential when they are also applicable to full neural networks. \\
While the primary reason for these evaluations and validations is to establish the capabilities and limitations of the specific predictors trained in this work, they also serve to establish the soundness of the approach and methodology on a broader level, demonstrating their suitability as a base for future work.


\section{Outlook}
The nature of this work opens up a number of avenues for future work. In light of our goal to guide towards the use of the best fitting hardware for specific tasks and requirements, the most promising avenue is to expand the study to a larger number of hardware platforms. The lowest friction way of doing that would be to collect datasets for further Nvidia GPUs at their default clocks and adding the GPU model as a parameter to the prediction model, in the same way the clock speed was added for the A30 predictor. \\
Another direction could be an attempt to improve the prediction performance.
A good starting point would be the expansion of the set of model-input sets which were used to build the training set for the predictors in this work. Including operations from more model-input sets, especially types of models not included in this work, could go a long way towards improving the predictor's accuracy and generalizability beyond its current state. \\
Even though we limited our GPU clock study to the A30 in this work, there is no conceptual reason why these kinds of clock speed studies could not be expanded to a more GPUs, as long as they support setting the clock speed manually. This kind of study always carries the chance of discovering interesting patterns and behaviors.\\
Another avenue for expansion are the metrics included in the study. The metrics used in our work were fixed from a very early point onward. It covers time, power and energy. A prime candidate for the next metric to add would be the memory usage. \\
The complexity in the addition of further metrics lies in the tooling. The more tools are used, the harder expansion towards additional hardware platforms becomes. \\
The last and widest avenue for expansion is the inclusion of more hardware platforms. Our current tooling for power readout is Nvidia specific, but provided equivalent tools, an expansion towards GPUs from different manufacturers like AMD and Intel would be very interesting. Combined with real-time pricing this would allow determining the most cost effective GPU for a specific task including power costs across the entire GPU market. \\
The last and most difficult step is moving from GPU studies towards the inclusion of CPUs and more exotic accelerators like FPGAs and IPUs. This step will be the most limiting to our selection of suitable metrics, since they all need to be meaningfully applicable to all included hardware platforms. Expanding the number and types of hardware platforms is the most fascinating avenue for future work, but it is also the one moving the furthest away from the foundation presented in this work and the least predictable in its development. \\
In summary, there are many opportunities for future expansion upon the basis presented here. Some of them will require a lot of additional work, while others are direct continuations, which should present minimal friction.

\section{Conclusion}


We identified the research gap as the lack of works covering performance predictions for runtime and energy for both training and inference workloads. In order to address this, we designed our profiling and prediction frameworks to cover time, power and energy for both inference and training operations. \\
Our first contribution covers the profiling part of this work. Here we presented our method for collecting a dataset of individual operations which serves as training data for our predictor. The second contribution presents our choice of the random forest model for our predictor, as well as the preprocessing of the dataset. Our third and largest contribution is focused on validating and evaluating the work product of the first two contributions. It contains a validation of the dataset quality through comparisons between direct measurements of full neural network runs and summed up operations-level profiling results. The random forest predictor models are evaluated via $R^2$ score with both cross-validation and test set performance on the operations level. On the neural network level, a set of unknown model-input sets is used to validate the predictor performance by comparing direct measurements of the full neural network runs to the summed up operations-level predictions. Profiling over a number of clock speeds also yielded the insight, that 900 MHz is the most energy efficient setting on the A30 across all model-input sets used for the validation. \\
With $R^2$ scores of $0.7$ to $0.9$ for runtime predictions and $0.90$ to $0.98$ for power predictions on the operations level, we already contribute a tool which can be of considerable help in deciding which GPU and which clock speed to run a specific model at. Additionally the raw profiling data itself bears the potential of providing insight into useful patterns like the most energy efficient clock speed or the optimal clock setting for a minimal energy delay product. \\
Our work serves as an exploratory and foundational step into the profiling and prediction of an ever broadening zoo of parameter combinations between models, inputs, hardware platforms, clock settings, metrics and workload types. And while we contribute valuable findings and tools towards that goal, the available research potential in this field is far from exhausted and we hope our findings and contributions can help to pave the way and guide future researchers in search of that same goal.